# MCM-2025-Junior-Group-Question-2_Reinforcment-Learning
##1.this file are structured as below:
mcm_game_ai/

â”œâ”€â”€ core/

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ game.py

â”‚   â”œâ”€â”€ mcts_net.py

â”‚   â””â”€â”€ gnn_model.py

â”œâ”€â”€ agents/

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ policy_net.py

â”‚   â””â”€â”€ train_marl.py

â”œâ”€â”€ explain/

â”‚   â”œâ”€â”€ __init__.py

â”‚   â””â”€â”€ strategy_explainer.py

â”œâ”€â”€ web/

â”‚   â””â”€â”€ app.py

â”œâ”€â”€ data_output/

â”‚   â”œâ”€â”€ alice_policy.pth

â”‚   â”œâ”€â”€ bob_policy.pth

â”‚   â”œâ”€â”€ game_logs.jsonl

â”‚   â””â”€â”€ test.txt

â”œâ”€â”€ analysis/

â”‚   â”œâ”€â”€ question_q2

â”‚   â””â”€â”€ discover_strategy.py

â”œâ”€â”€ config.py

â”œâ”€â”€ analyze_logs.py

â”œâ”€â”€ forevr_train.py

â””â”€â”€ README.md

##2.Here is a brief description of the main scripts in the repository:


train_marl.py
**Multi-Agent Reinforcement Learning Trainer**

Trains Alice and Bob (two neural agents) through self-play in the competitive 1-100 number chain game. Uses policy gradient with strategic reward shaping (win bonus, prime control, chain length). Implements adaptive opponent evolution: every 1000 episodes, Bob inherits Alice's policy with noise to become a stronger challenger.

Key features: Action masking for valid moves, MLP policy network, Adam optimizer.


analysis/answer_q2.py
**Strategy Analysis & Performance Evaluation**

Analyzes trained policies and extracts key insights for Question 2. Computes Alice's win rate, average scores, chain lengths, and identifies high-frequency optimal opening moves (e.g., 64, 97). Generates statistical summaries used in the final report.

Ideal for generating data to support claims about strategic behavior.


forever_train.py
**Long-Term Policy Evolution & Robustness Training**

Extends training over many iterations with periodic evaluation and policy saving. Designed for long-horizon refinement and stability testing. Logs performance every 500 episodes and saves best models, enabling analysis of learning progression and strategy convergence.

**Tip:** Run train_marl.py first to get initial policies, then use answer_q2.py for analysis. Use forever_train.py for extended training and robustness validation.


##3. ğŸš€ How to Run This Project

This guide walks you through setting up the environment and running the key scripts. All code is written in Python.

---

### 1. ğŸ› ï¸ Prerequisites

- **Python 3.8 or higher**
- (Optional) **CUDA-enabled GPU** for faster training (but CPU is supported)

---

### 2. ğŸ“¦ Install Dependencies

#### clone the repo
```bash
git clone https://github.com/Jincan_LI_HUB/mcm-game-ai.git
cd mcm-game-ai
